{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import pickle\n",
    "from functools import partial\n",
    "\n",
    "from dgp import get_dataloader\n",
    "from utils.llc import calculate_llc_for_file\n",
    "from utils.loading import Conf, load_model_from_hf\n",
    "from utils import move_to_device\n",
    "\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "hf_repo_name = \"cybershiptrooper/ConceptPerlocation_ckpts_98k\"\n",
    "dump_dir = f\"results/scratch/{hf_repo_name}/llc\"\n",
    "model_dir = f\"results/scratch/{hf_repo_name}\"\n",
    "\n",
    "\n",
    "os.makedirs(dump_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "model = load_model_from_hf(0, hf_repo_name, epoch=0)\n",
    "config = Conf(**model[\"config\"])\n",
    "\n",
    "config.device = device\n",
    "\n",
    "dataloader = get_dataloader(\n",
    "    n_relative_properties=config.data.n_relative_properties,\n",
    "    n_descriptive_properties=config.data.n_descriptive_properties,\n",
    "    n_descriptive_values=config.data.n_descriptive_values,\n",
    "    num_of_classes_to_divide_over=config.data.num_of_classes_to_divide_over,\n",
    "    prior_param=config.data.prior_param,\n",
    "    props_prior_type=config.data.props_prior_type,\n",
    "    n_entities=config.data.n_entities,\n",
    "    instr_ratio=config.data.instr_ratio,\n",
    "    max_sample_length=config.data.max_sample_length,\n",
    "    num_iters=5e5 * config.data.batch_size,\n",
    "    batch_size=config.data.batch_size,\n",
    "    num_workers=config.data.num_workers,\n",
    "    seed=config.seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "pad_token_id = dataloader.dataset.pad_token_id\n",
    "\n",
    "\n",
    "def evaluate_fn(model, data, pad_token_id, config):\n",
    "    sequences, symb_sequences, seq_lengths, seq_logprobs, _ = data\n",
    "    B = sequences.size(0)\n",
    "    inputs, labels = move_to_device([sequences[:, :-1], sequences[:, 1:]], config.device)\n",
    "    labels = labels.clone()\n",
    "    labels[labels == pad_token_id] = -100  # Mask padding\n",
    "    logits = model(inputs)  # (B, L-1, V)\n",
    "    loss = F.cross_entropy(\n",
    "        logits.reshape(-1, logits.size(-1)),\n",
    "        labels.reshape(-1),\n",
    "        ignore_index=-100,\n",
    "        reduction=\"none\",\n",
    "    )  # (B*L-1)\n",
    "    loss = loss.reshape(B, -1).mean()\n",
    "    return loss, {}\n",
    "\n",
    "\n",
    "evaluator = partial(evaluate_fn, pad_token_id=pad_token_id, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from tqdm import tqdm\n",
    "\n",
    "llc_outputs = []\n",
    "iters = (\n",
    "    list(range(0, 200, 10))\n",
    "    + list(range(200, 1200, 20))\n",
    "    + list(range(1200, 5_001, 50))\n",
    "    + list(range(5_100, 10_001, 100))\n",
    "    + list(range(10_500, 25_501, 500))\n",
    "    + list(range(86_000, 100_501, 1000))\n",
    ")\n",
    "for iter in tqdm(iters):\n",
    "    print(f\"Calculating LLC for iteration {iter}\")\n",
    "    llc_output = calculate_llc_for_file(\n",
    "        iter,\n",
    "        dataloader,\n",
    "        model_dir=hf_repo_name,\n",
    "        config=config,\n",
    "        evaluate_fn=evaluator,\n",
    "        model_loader=load_model_from_hf,\n",
    "        num_chains=5,\n",
    "        num_draws=200,\n",
    "    )\n",
    "    llc_outputs.append(llc_output)\n",
    "    with open(f\"{dump_dir}/llc_output_it_{iter}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(llc_output, f)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
